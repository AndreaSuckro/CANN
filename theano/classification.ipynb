{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theano example implementation for data classification\n",
    "\n",
    "This example should illustrate the functionality of Theano on the TensorFlow examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing all the things\n",
    "%matplotlib notebook\n",
    "\n",
    "import theano\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "import numpy.random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniform = lambda a,b,n=1: (b-a) * rand.random_sample((1,n)) + a\n",
    "\n",
    "n = 200 # datapoints per category\n",
    "\n",
    "# circle data\n",
    "radius = 5\n",
    "r = np.append(uniform(0, radius*.5, n//2), uniform(radius*.7, radius, n//2))\n",
    "angle = uniform(0, 2*np.pi, n)\n",
    "xy = np.vstack((r * np.sin(angle), r * np.cos(angle)))\n",
    "t = np.less(la.norm(xy, axis=0), radius*.5)\n",
    "circle = (xy.T, t)\n",
    "\n",
    "# xor data\n",
    "padding = .3\n",
    "x = uniform(-5, 5, n); x[x>padding] += padding; x[x<padding] -= padding\n",
    "y = uniform(-5, 5, n); y[y>padding] += padding; y[y<padding] -= padding\n",
    "t = np.less(x*y, 0).flatten()\n",
    "xor = (np.vstack((x, y)).T, t)\n",
    "\n",
    "# gauss data\n",
    "gauss = (np.vstack((rand.normal(2, 1, (n//2, 2)), rand.normal(-2, 1, (n//2, 2)))),\n",
    "         np.append(np.ones(n//2), np.zeros(n//2)))\n",
    "\n",
    "# spiral data\n",
    "def genSpiral(deltaT, n, noise = 0):\n",
    "    points = np.arange(n)\n",
    "    r = points / n * 5\n",
    "    t = 1.75 * points / n * 2 * np.pi + deltaT\n",
    "    return np.vstack((r * np.sin(t), r * np.cos(t))).T\n",
    "spiral = (np.vstack((genSpiral(0, n//2), genSpiral(np.pi, n//2))),\n",
    "          np.append(np.ones(n//2), np.zeros(n//2)))\n",
    "\n",
    "# Visualize\n",
    "fig = plt.figure('Available Datasets')\n",
    "ax1 = plt.subplot(221); ax1.set_title('circle')\n",
    "ax1.scatter(*zip(*circle[0]), c=circle[1], cmap='bwr')\n",
    "ax2 = plt.subplot(222); ax2.set_title('xor')\n",
    "ax2.scatter(*zip(*xor[0]), c=xor[1], cmap='bwr')\n",
    "ax3 = plt.subplot(223); ax3.set_title('gauss')\n",
    "ax3.scatter(*zip(*gauss[0]), c=gauss[1], cmap='bwr')\n",
    "ax4 = plt.subplot(224); ax4.set_title('spiral')\n",
    "ax4.scatter(*zip(*spiral[0]), c=spiral[1], cmap='bwr')\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# debug settings (not that it would help a lot...)\n",
    "theano.config.exception_verbosity='high'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first implementation here shows a simple perceptron implementation in Theano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LINEAR REGRESSION\n",
    "\n",
    "N = 400 # number of samples\n",
    "feats = 20 # dimensionality of features\n",
    "D = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2)) # rand data\n",
    "training_steps = 10000\n",
    "\n",
    "x = T.matrix(\"x\")\n",
    "y = T.vector(\"y\")\n",
    "w = theano.shared(rng.randn(20), name=\"w\")\n",
    "b = theano.shared(0., name=\"b\")\n",
    "\n",
    "print(\"-------- Perceptron Model --------\")\n",
    "print(w.get_value(), b.get_value())\n",
    "\n",
    "p_1 = 1 / (1 + T.exp(-T.dot(x, w)-b)) # probability that target = 1\n",
    "prediction = p_1 > 0.5 # the prediction threshold\n",
    "xent = -y*T.log(p_1) - (1-y)*T.log(1-p_1) # cross-entropy loss func\n",
    "cost = xent.mean() + 0.01 * (w**2).sum() # the cost to minimize\n",
    "gw, gb = T.grad(cost, [w, b])\n",
    "\n",
    "train = theano.function(inputs = [x, y], outputs = [prediction, xent],\n",
    "                        updates = {w : w-0.1*gw, b : b-0.1*gb})\n",
    "\n",
    "predict = theano.function(inputs = [x], outputs = prediction)\n",
    "\n",
    "\n",
    "for i in range(training_steps):\n",
    "    pred, err = train(D[0], D[1])\n",
    "    \n",
    "print(\"-------- Training result -------\")\n",
    "print(w.get_value(), b.get_value())\n",
    "print(\"Target values for the data: \")\n",
    "print(D[1])\n",
    "print(\"Predictions on the data: \")\n",
    "print(predict(D[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's extend it to the MLP with the data given above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## MULTILAYER-PERCEPTRON\n",
    "\n",
    "# define the data\n",
    "N = 400\n",
    "feats = 2\n",
    "\n",
    "data, labels = xor\n",
    "D = (data, labels)\n",
    "\n",
    "x = T.matrix(\"x\")\n",
    "y = T.vector(\"y\")\n",
    "w_1 = theano.shared(rnd.randn(2,10), name=\"w1\")\n",
    "b_1 = theano.shared(np.zeros((10,)), name=\"b1\")\n",
    "w_2 = theano.shared(rnd.randn(10), name=\"w2\")\n",
    "b_2 = theano.shared(0., name=\"b2\")\n",
    "\n",
    "print(\"-------- Multilayer Model --------\")\n",
    "print(w_1.get_value(), b_1.get_value())\n",
    "print(w_2.get_value(), b_2.get_value())\n",
    "\n",
    "# expression graph for forward propagation\n",
    "out = T.nnet.sigmoid(-T.dot(T.nnet.sigmoid(-T.dot(x,w_1)-b_1), w_2)-b_2)\n",
    "\n",
    "prediction = out > 0.5\n",
    "\n",
    "# cross entropy as loss function\n",
    "cross_ent = -y * T.log(out) - (1-y) * T.log(1-out)\n",
    "# cost function\n",
    "cost = cross_ent.mean() + 0.01 * (w**2).sum()\n",
    "gw_1, gb_1, gw_2, gb_2 = T.grad(cost, [w_1, b_1, w_2, b_2])\n",
    "\n",
    "eps = 0.1\n",
    "steps = 10000\n",
    "\n",
    "# compile the model\n",
    "train = theano.function(inputs = [x, y], outputs = [prediction, cross_ent],\n",
    "                        updates = [(w_1, w_1-0.1*gw_1), (b_1, b_1-0.1*gb_1),\n",
    "                                   (w_2, w_2-0.1*gw_2), (b_2, b_2-0.1*gb_2)])\n",
    "\n",
    "predict = theano.function([x], prediction)\n",
    "\n",
    "for i in range(steps):\n",
    "    pred, err = train(D[0], D[1])\n",
    "\n",
    "print(\"-------- Training result -------\")\n",
    "print(w_1.get_value(), b_1.get_value())\n",
    "print(w_2.get_value(), b_2.get_value())\n",
    "\n",
    "print(\"Target values for the data: \")\n",
    "print(D[1])\n",
    "print(\"Predictions on the data: \")\n",
    "print(predict(D[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
