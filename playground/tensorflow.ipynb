{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Playground\n",
    "Welcome to the TensorFlow Playground! This notebook is modeled after the [TensorFlow Playground we application](http://playground.tensorflow.org) which offers a playful way to test different feed forward neural network configurations. Although the app was created by the TensorFlow guys, it does not actually use the library itself. This notebook gives you the opportunity to actually implement different network configurations you might already have tested in the web app. Along this notebook you will also find implementations of the playground in Keras and Theano. Tensorflow lies somewhere inbetween the two in a sense of abstractness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "As with the original web application you have the choice between four different datasets. The next cell visualizes them and in the cell right below you can specify your choice. To use anything but the gauss dataset you can simply exchange the `datasets.gauss` function call with either `datasets.circle`, `datasets.xor` or `datasets.spiral`. Additionally you can add some noise to the data to make the problem more difficult. Some information about the provided data structures:\n",
    "\n",
    "The two `*_data` variables contain the actual data in 2 dimensional numpy arrays or shape `(*,2)`. The first axis describes individual observations and the second axis the `x` and `y` values. The `*_labels` variables are simply `(*,1)` numpy arrays specifying a label, `0` or `1`, for each sample. The size of the first axis for both results from the train/test split.\n",
    "\n",
    "As the names suggest, `train_data` and `train_labels` are designated for training and contain a lot more data (by default $9/10$) and `test_data` and `test_labels` are meant for evaluating the networks performance. You can change the amount of samples inside the `gauss` (or whatever you chose) function call and also adjust the split between training and testing data by adjusting the second parameter for the `datasets.split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt\n",
    "from playground import DataGenerator\n",
    "\n",
    "datasets = DataGenerator()\n",
    "\n",
    "fig = plt.figure('Available Datasets')\n",
    "for i, name in enumerate(['circle', 'xor', 'gauss', 'spiral']):\n",
    "    data, labels = getattr(datasets, name)(200)\n",
    "    axis = plt.subplot(221+i)\n",
    "    axis.set_title(name)\n",
    "    axis.scatter(*zip(*data), c=labels, cmap='bwr')\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# datasets.circle(), datasets.xor(), datasets.gauss(), datasets.spiral()\n",
    "data, labels = datasets.gauss(n=1000, noise=0)\n",
    "(train_data, train_labels), (test_data, test_labels) = datasets.split((data, labels), 10)\n",
    "\n",
    "fig = plt.figure('Chosen dataset')\n",
    "plt.scatter(*zip(*data), c=labels, cmap='bwr')\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's your turn!\n",
    "In the next cell stuff gets interesting. We preimplemented a basic model which is sufficiently powerful for the gauss dataset. It consists of 2 neurons in the input layer to feed `x` and `y` values into, 4 neurons in the single hidden layer and a single neuron in the output layer.\n",
    "\n",
    "Instead of using buttons and dropdowns you will need to get your hands dirty here in order to cope with more complex datasets! While we provide some guidance to mock the experience of the web application it will be also super useful to checkout the [TensorFlow API documentation](https://www.tensorflow.org/versions/r0.9/api_docs/index.html). Because the documentation does not give any theoretical background on all those different functions you might also want to regularily consultate Wikipedia.\n",
    "\n",
    "Some ideas on what you can play around with:\n",
    "\n",
    "  * First take a general look through the code and play with stuff which is not TensorFlow specific. You can for example change the amount of training epochs and the size of the batch the network is trained with in every iteration. Also: If your computer struggles with the computations you might want to consider removing the progress visualization.\n",
    "  * Adjust the hidden layer, play around with more or even fewer neurons.\n",
    "  * Add another hidden layer or remove the existing one. You will need to adjust the matrix multiplications for its surrounding layers in order to incorporate the change into the network.\n",
    "  * Change the activation functions. By default both, the hidden and the output layer, use the sigmoid activation function. Similar to the web application you can use `relu` or `tanh`. You might also consider trying to implement your own `linear` activation function -- TensorFlow does not provide one by itself.\n",
    "  * Take a look into different error measures and optimizers. This is nothing you can change in the playground web application but actually a powerful tool to tweak your networks performance through better training. Checkout the [optimizers chapter](https://www.tensorflow.org/versions/r0.9/api_docs/python/train.html#optimizers) in the documentation.\n",
    "\n",
    "When you solved all the datasets you can also start adding noise to the data or take less data for training by adjusting the test/train split (see the code cell above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import permutation\n",
    "from playground import viz\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 2], name='input_layer')\n",
    "\n",
    "W_h = tf.Variable(tf.random_normal([2,4]), name='hidden_weights')\n",
    "b_h = tf.Variable(tf.zeros([4]), name='hidden_bias')\n",
    "h = tf.nn.sigmoid(tf.matmul(x,W_h) + b_h, name='hidden_layer')\n",
    "\n",
    "W_y = tf.Variable(tf.random_normal([4,1]), name='output_weights')\n",
    "b_y = tf.Variable(tf.zeros([1]), name='output_bias')\n",
    "y = tf.nn.sigmoid(tf.matmul(h,W_y) + b_y, name='output_layer')\n",
    "\n",
    "t = tf.placeholder(tf.float32, shape=[None, 1], name='targets')\n",
    "\n",
    "error = tf.reduce_mean(tf.squared_difference(t,y), name='mean_squared_error')\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.03).minimize(error, name='gradient_descent')\n",
    "\n",
    "prediction_check = tf.equal(tf.round(y), t, name='prediction_check')\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_check, tf.float32), name='accuracy_measure')\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "fig = plt.figure('Result')\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    split = permutation(len(train_labels))\n",
    "    batch_labels = train_labels[split[:10]]\n",
    "    batch_data = train_data[split[:10]]\n",
    "    sess.run(optimizer, {x: batch_data, t: batch_labels})\n",
    "    if (epoch+1)%100 == 0 or (epoch+1) == epochs:\n",
    "        perf = sess.run(accuracy, {x: test_data, t: test_labels})\n",
    "        predictions = sess.run(y, {x: data})\n",
    "        viz(data, predictions, (epoch+1)/epochs, perf, fig, discretize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
