{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Playground\n",
    "Welcome to the Keras Playground! This notebook is modeled after the [TensorFlow Playground web application](http://playground.tensorflow.org) which offers a playful way to test different feed forward neural network configurations. This notebook gives you the opportunity to actually implement different network configurations you might already have tested in the web app. Along this notebook you will also find implementations of the playground in TensorFlow and Theano. Keras has the highest level of abstractation of the three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "As with the original web application you have the choice between four different datasets. The next cell visualizes them and in the cell right below you can specify your choice. To use anything but the gauss dataset you can simply exchange the `datasets.gauss` function call with either `datasets.circle`, `datasets.xor` or `datasets.spiral`. Additionally you can add some noise to the data to make the problem more difficult. Some information about the provided data structures:\n",
    "\n",
    "The two `data` variable contains the actual data in a 2 dimensional numpy array of shape `(n,2)`. The first axis describes individual observations and the second axis the `x` and `y` values. The `labels` variable is simply a `(n,1)` numpy array specifying a label, `0` or `1`, for each sample. `n` simply describes the amount of observations, adjust it in the `dataset.gauss` (or whatever you chose) function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from playground import DataGenerator\n",
    "\n",
    "datasets = DataGenerator()\n",
    "\n",
    "fig = plt.figure('Available Datasets')\n",
    "for i, name in enumerate(['circle', 'xor', 'gauss', 'spiral']):\n",
    "    data, labels = getattr(datasets, name)(200)\n",
    "    axis = plt.subplot(221+i)\n",
    "    axis.set_title(name)\n",
    "    axis.scatter(*zip(*data), c=labels, cmap='bwr')\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# datasets.circle(), datasets.xor(), datasets.gauss(), datasets.spiral()\n",
    "data, labels = datasets.gauss(n=2000, noise=0)\n",
    "\n",
    "plt.figure('Chosen dataset')\n",
    "plt.scatter(*zip(*data), c=labels, cmap='bwr')\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we go!\n",
    "Below we implemented a basic neural network consisting of two neurons in the input, 4 in the single hidden and 1 in the output layer. Both layers, hidden and output, use a sigmoid activation and we use stochastic gradient descent with the mean squared error function as loss function.\n",
    "\n",
    "Go ahead and try to different network configurations for different datasets. Use less epochs and check which activation function and which layer sizes and amounts give you the best results. What are minimal configurations which still give good performances at the end?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(4, input_dim=2),\n",
    "    Activation('sigmoid'),\n",
    "    Dense(1),\n",
    "    Activation('sigmoid'),\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "sgd = SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "model.compile(optimizer=sgd, loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    data, \n",
    "    labels,\n",
    "    batch_size=10,\n",
    "    nb_epoch=1000, \n",
    "    verbose=0, \n",
    "    shuffle=True, \n",
    "    validation_split=0\n",
    ")\n",
    "\n",
    "predictions = model.predict(data)\n",
    "accuracy = np.mean(predictions.round()==labels)\n",
    "\n",
    "fig = plt.figure('Result')\n",
    "fig.suptitle('Accuracy {:2.4f}'.format(accuracy))\n",
    "plt.scatter(*zip(*data), c=predictions, cmap='bwr')\n",
    "fig.canvas.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
